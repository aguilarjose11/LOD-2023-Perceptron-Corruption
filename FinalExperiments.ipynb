{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae4ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "import Perceptron.perceptron as pn\n",
    "from Perceptron.data_gen import Universe, separable_regression, data_distribution\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, zero_one_loss\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "## Data Corruption Experiment\n",
    "from typing import List, Tuple\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a934ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def pickle_data(\n",
    "    root_dir, \n",
    "    results,\n",
    "    args):\n",
    "    \n",
    "    # Make sure it is a directory!\n",
    "    if root_dir[-1] != '/':\n",
    "        root_dir += '/'\n",
    "    \n",
    "    # Create pickle structure\n",
    "    pkl = {\n",
    "        'results': dict(results),\n",
    "        'args':    args,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Create file name\n",
    "\n",
    "    file_name = f\"{args.label}_test_size_{args.test_size}.pkl\"\n",
    "    \n",
    "    with open(f\"{root_dir}{file_name}\", 'wb') as pkl_file:\n",
    "        pickle.dump(pkl, pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025ea4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment required functions\n",
    "def sample_data(\n",
    "    lows:      List[float],\n",
    "    highs:     List[float],\n",
    "    n_samples: int,\n",
    "    seed:      int=None\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"Sample uniform distribution bounded by lows and highs\n",
    "    \n",
    "        Using a uniform distribution, perform sampling over the \n",
    "    distribution such that the space the distribution is sampling will \n",
    "    be bounded by the given bounds from the lows and highs. Lows and \n",
    "    highs will be arrays that contain the minimum and maximum values \n",
    "    per dimension on the data to be samples. For example, if we have 4 \n",
    "    values in both lows and highs, then, at the time of sampling n_samples\n",
    "    samples we will have n_samples of 4 attributes each: (n_samples, 4).\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(lows) == len(highs), f\"Non-matching lows and highs: {len(lows) != {len(highs)}}\"\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    data_shape = (n_samples, len(lows)) # See assertion #1\n",
    "    data = rng.uniform(lows, highs, data_shape)\n",
    "    return data\n",
    "\n",
    "# splitting the dataset into bins can be done with: np.split(data, n_buckets)\n",
    "# Recommend shuffling beforehand tho.\n",
    "\n",
    "class Concept:\n",
    "    \"\"\"Label given data\n",
    "    Using a model as truth, label given data.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        return self.model.solve(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff90593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_118573/3073147010.py\u001b[0m(34)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     32 \u001b[0;31m\u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbuckets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m        \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0mremaining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(remaining_data)\n",
      "[[-6.00183595 -9.8527546   5.73848755  3.29701713  1.        ]\n",
      " [ 5.61458062 -0.82168449  1.37482392 -7.20406004  1.        ]\n",
      " [ 3.36805924 -0.57807588  1.30472213  5.29997715  1.        ]\n",
      " [ 1.07158801  1.18414321 -3.92099804 -9.38364331  1.        ]\n",
      " [-5.70830654 -1.82942713  7.06806147 -5.32121028  1.        ]\n",
      " [-4.37232216 -4.12812484  3.23833029  1.14064305  1.        ]\n",
      " [ 3.28627081 -1.87226277  6.28040769 -6.6605416   1.        ]\n",
      " [-8.19904278  4.44718701 -0.76245539 -6.77456442  1.        ]\n",
      " [-6.95375795  3.9264075  -1.07687449 -2.37957548  1.        ]\n",
      " [ 2.60565186 -2.76374779 -8.24700161 -7.63988196  1.        ]]\n",
      "ipdb> c\n",
      "> \u001b[0;32m/tmp/ipykernel_118573/3073147010.py\u001b[0m(34)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     32 \u001b[0;31m\u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbuckets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m        \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0mremaining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(remaining_data)\n",
      "[[ 5.57992709 -7.30895583  0.72136072  0.2844574   1.        ]\n",
      " [-0.74401269 -2.29821008  2.79126542 -4.67073365  1.        ]\n",
      " [-0.44245452 -1.66221263 -5.34860119 -2.6497638   1.        ]\n",
      " [-3.45008871 -2.41071841  3.71486691 -4.06247051  1.        ]\n",
      " [ 8.32696039 -0.38179143 -3.4327759   0.7086958   1.        ]\n",
      " [ 3.05174681  6.08783656  0.65444552  2.65835259  1.        ]\n",
      " [ 4.69786325 -5.95190814  3.89596258  7.21438137  1.        ]\n",
      " [ 2.28759481 -8.09808504  4.51431257 -8.31013562  1.        ]\n",
      " [-7.2518414   9.17760492  6.01768352  1.87364009  1.        ]\n",
      " [ 5.90229678  8.92054126 -4.93233292  1.80151791  1.        ]\n",
      " [ 2.323314   -6.57417392  1.29901223  1.44861028  1.        ]\n",
      " [ 0.45263551  5.2784678   5.98489433 -0.15693569  1.        ]\n",
      " [ 8.62472471 -7.60532823 -7.65792868 -8.24581976  1.        ]\n",
      " [-1.62783398  5.48642832  3.42462827 -3.32724483  1.        ]\n",
      " [ 5.25064294 -4.58930118 -2.71615964 -3.7112004   1.        ]\n",
      " [-7.04433255  8.72254927 -1.24191926 -2.33360354  1.        ]\n",
      " [ 1.05986131  8.72279974  5.60602988 -0.41260872  1.        ]\n",
      " [ 9.7326309   4.35520472  9.0238932  -7.63042846  1.        ]\n",
      " [ 2.74147768 -7.56156643  1.76516     3.7219273   1.        ]\n",
      " [-0.91364076  6.50799022 -4.09281949 -0.82903836  1.        ]]\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "> \u001b[0;32m/tmp/ipykernel_118573/3073147010.py\u001b[0m(34)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     32 \u001b[0;31m\u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mbuckets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m        \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0mremaining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed) \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m buckets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_buckets):\n\u001b[1;32m     35\u001b[0m         indices \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_buckets), size\u001b[38;5;241m=\u001b[39mbuckets, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m         remaining_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(train_data[indices])\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed) \u001b[38;5;66;03m# For reproducibility\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m buckets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_buckets):\n\u001b[1;32m     35\u001b[0m         indices \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_buckets), size\u001b[38;5;241m=\u001b[39mbuckets, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m         remaining_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(train_data[indices])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/bdb.py:88\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/bdb.py:113\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up learning concept\n",
    "ins = 4 + 1 # +1 because of bias!\n",
    "rng = np.random.default_rng(42) # For reproducibility\n",
    "W = np.concatenate([rng.uniform(-100, 100, (ins-1, 1)), [[1]]])\n",
    "\n",
    "truth = pn.PocketPerceptron()\n",
    "truth.pi = truth.W = W\n",
    "c = Concept(truth)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "lows  = [-10, -10, -10, -10] + [1]\n",
    "highs = [10, 10, 10, 10] + [1]\n",
    "n_samples = 100\n",
    "n_buckets = 10\n",
    "\n",
    "assert len(lows) == len(highs) == ins, \\\n",
    "    f\"Data dimensions do not match concept's: {ins} vs {len(lows)} vs {len(highs)}\"\n",
    "# We sample separately the data from the uniform distribution. Then, we label according\n",
    "# to the concept (perceptron with weights W)\n",
    "train_data   = sample_data(lows, highs, n_samples=n_samples, seed=42)\n",
    "train_data   = np.split(train_data, n_buckets)\n",
    "train_data   = np.array(train_data)\n",
    "train_labels = c(train_data)\n",
    "test_data    = sample_data(lows, highs, n_samples=n_samples//6, seed=42)\n",
    "test_labels  = c(test_data)\n",
    "\n",
    "# Experiment\n",
    "n_runs = 25\n",
    "seed = 42\n",
    "\n",
    "rng = np.random.default_rng(seed) # For reproducibility\n",
    "for run in range(n_runs):\n",
    "    for buckets in range(1, n_buckets):\n",
    "        indices = rng.choice(range(1, n_buckets), size=buckets, replace=False)\n",
    "        remaining_data = np.concatenate(train_data[indices])\n",
    "        # Data correctly reshapes to be put together.\n",
    "        \n",
    "\n",
    "# Note: train_data has buckets, test_data does not: only instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62d0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment(\n",
    "    X,\n",
    "    y,\n",
    "    metric,\n",
    "    test_split:   float,\n",
    "    buckets:       int,\n",
    "    n_runs:        int,\n",
    "    verbose:       bool,\n",
    "    n_buckets:     int, \n",
    "    max_iter:      int,\n",
    "    eta:           float,\n",
    "    ):\n",
    "    \n",
    "    assert len(X) == len(y), 'Shapes of input data and labels does not match!'\n",
    "    \n",
    "    # Bukcetize data\n",
    "    training_size = int(len(X)*0.8)\n",
    "    testing_size  = len(X) - training_size \n",
    "    train, test = corrupt_data(universe_len=len(X), \n",
    "                               buckets=buckets,\n",
    "                               test_split=test_split)\n",
    "    \n",
    "    # Create dictionary to store results\n",
    "    exp_data = defaultdict(lambda : [])\n",
    "    \n",
    "    # Experiment\n",
    "    for run in range(n_runs):\n",
    "        if verbose > 0:\n",
    "            print(f\"Start of run {run}.\")\n",
    "        \n",
    "        \n",
    "        # begin bining\n",
    "        empirical_score = []\n",
    "        for bins in range(1, n_buckets):\n",
    "\n",
    "            # Create model; No innate bias included!\n",
    "            model = pn.PocketPerceptron(\n",
    "                input=X.shape[-1], \n",
    "                eta=eta, \n",
    "                max_iter=max_iter\n",
    "            ) \n",
    "            \n",
    "            # Grab training data\n",
    "            m      = np.concatenate(X[train[:bins]])\n",
    "            labels = np.concatenate(y[train[:bins]])\n",
    "            \n",
    "            if verbose > 1:\n",
    "                print(f\"Training with {bins} buckets -- {len(m)}\")\n",
    "            \n",
    "            # Train model\n",
    "            model.train(m, labels)\n",
    "            \n",
    "            # Store risk data\n",
    "            if testing_size: \n",
    "                pred = model.solve(X[test])\n",
    "                exp_data[bins].append(metric(y[test], pred))\n",
    "            \n",
    "            else: # No empirical testing. Take error over all data.\n",
    "                pred = model.solve(X)\n",
    "                exp_data[bins].append(metric(y, pred))\n",
    "\n",
    "            #true_score.append(accuracy_score(y, model.solve(X)))\n",
    "        #import pdb; pdb.set_trace()\n",
    "    return dict(exp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d891942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
